{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737cf401",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39e79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import relax\n",
    "from AllocationFinder import AllocationFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce3297",
   "metadata": {},
   "source": [
    "# Relax Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439f2dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #A2F\">@I</span><span style=\"color: #A2F; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #00F; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #A2F\">@R</span><span style=\"color: #A2F; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">forward</span>(x: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">-&gt;</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(x, conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>reshape(conv1_bias, R<span style=\"color: #A2F; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv2d: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv, lv1)\n",
       "            relu: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(conv2d)\n",
       "            lv2: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(relu, conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv3: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>reshape(conv2_bias, R<span style=\"color: #A2F; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv2d1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv2, lv3)\n",
       "            relu1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(conv2d1)\n",
       "            gv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> relu1\n",
       "            R<span style=\"color: #A2F; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RelaxMnist(relax.frontend.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelaxMnist, self).__init__()\n",
    "        self.conv1 = relax.frontend.nn.Conv2D(3, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.relu1 = relax.frontend.nn.ReLU()\n",
    "        self.conv2 = relax.frontend.nn.Conv2D(32, 64, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.relu2 = relax.frontend.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_shape = (1, 3, 128, 128)\n",
    "rconv_mod, rconv_params = RelaxMnist().export_tvm({\"forward\": {\"x\": relax.frontend.nn.spec.Tensor(input_shape, \"float32\")}})\n",
    "rconv_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bbd65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #A2F\">@I</span><span style=\"color: #A2F; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #00F; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">fused_conv2d1_add1_relu1</span>(relu: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_weight: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), lv3: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute_intermediate: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        pad_temp <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>)))\n",
       "        conv2d_nchw_intermediate <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        T_add_intermediate <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pad_temp&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(relu[v_i0, v_i1, v_i2 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), v_i3 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(pad_temp[v_i0, v_i1, v_i2, v_i3])\n",
       "                pad_temp[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>if_then_else(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">&lt;=</span> v_i2 <span style=\"color: #008000; font-weight: bold\">and</span> v_i2 <span style=\"color: #A2F; font-weight: bold\">&lt;</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">130</span>) <span style=\"color: #008000; font-weight: bold\">and</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">&lt;=</span> v_i3 <span style=\"color: #008000; font-weight: bold\">and</span> v_i3 <span style=\"color: #A2F; font-weight: bold\">&lt;</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">130</span>), relu[v_i0, v_i1, v_i2 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), v_i3 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)], T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> nn, ff, yy, xx, rc, ry, rx <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw&quot;</span>):\n",
       "                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRRR&quot;</span>, [nn, ff, yy, xx, rc, ry, rx])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(pad_temp[v_nn, v_rc, v_yy <span style=\"color: #A2F; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #A2F; font-weight: bold\">+</span> v_rx], conv2_weight[v_ff, v_rc, v_ry, v_rx])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>init():\n",
       "                    conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">=</span> conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">+</span> pad_temp[v_nn, v_rc, v_yy <span style=\"color: #A2F; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #A2F; font-weight: bold\">+</span> v_rx] <span style=\"color: #A2F; font-weight: bold\">*</span> conv2_weight[v_ff, v_rc, v_ry, v_rx]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [ax0, ax1, ax2, ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3[v_ax0, v_ax1, T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">+</span> lv3[v_ax0, v_ax1, T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>)]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(T_add_intermediate[v_i0, v_i1, v_i2, v_i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(compute_intermediate[v_i0, v_i1, v_i2, v_i3])\n",
       "                compute_intermediate[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>max(T_add_intermediate[v_i0, v_i1, v_i2, v_i3], T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">fused_conv2d_add_relu</span>(x: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_weight: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), lv1: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute_intermediate: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        pad_temp <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>)))\n",
       "        conv2d_nchw_intermediate <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        T_add_intermediate <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">132</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pad_temp&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(x[v_i0, v_i1, v_i2 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), v_i3 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(pad_temp[v_i0, v_i1, v_i2, v_i3])\n",
       "                pad_temp[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>if_then_else(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">&lt;=</span> v_i2 <span style=\"color: #008000; font-weight: bold\">and</span> v_i2 <span style=\"color: #A2F; font-weight: bold\">&lt;</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">130</span>) <span style=\"color: #008000; font-weight: bold\">and</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">&lt;=</span> v_i3 <span style=\"color: #008000; font-weight: bold\">and</span> v_i3 <span style=\"color: #A2F; font-weight: bold\">&lt;</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">130</span>), x[v_i0, v_i1, v_i2 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), v_i3 <span style=\"color: #A2F; font-weight: bold\">-</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)], T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> nn, ff, yy, xx, rc, ry, rx <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">5</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;conv2d_nchw&quot;</span>):\n",
       "                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRRR&quot;</span>, [nn, ff, yy, xx, rc, ry, rx])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(pad_temp[v_nn, v_rc, v_yy <span style=\"color: #A2F; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #A2F; font-weight: bold\">+</span> v_rx], conv1_weight[v_ff, v_rc, v_ry, v_rx])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>init():\n",
       "                    conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">=</span> conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] <span style=\"color: #A2F; font-weight: bold\">+</span> pad_temp[v_nn, v_rc, v_yy <span style=\"color: #A2F; font-weight: bold\">+</span> v_ry, v_xx <span style=\"color: #A2F; font-weight: bold\">+</span> v_rx] <span style=\"color: #A2F; font-weight: bold\">*</span> conv1_weight[v_ff, v_rc, v_ry, v_rx]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [ax0, ax1, ax2, ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv1[v_ax0, v_ax1, T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">+</span> lv1[v_ax0, v_ax1, T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">0</span>)]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1, v_i2, v_i3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(T_add_intermediate[v_i0, v_i1, v_i2, v_i3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(compute_intermediate[v_i0, v_i1, v_i2, v_i3])\n",
       "                compute_intermediate[v_i0, v_i1, v_i2, v_i3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>max(T_add_intermediate[v_i0, v_i1, v_i2, v_i3], T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">reshape</span>(conv1_bias: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_reshape: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;op_pattern&quot;</span>: <span style=\"color: #008000\">2</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_reshape&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [ax0, ax1, ax2, ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(conv1_bias[(v_ax1 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax2 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax3) <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> conv1_bias[(v_ax1 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax2 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax3) <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">32</span>)]\n",
       "\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">reshape1</span>(conv2_bias: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_reshape: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;op_pattern&quot;</span>: <span style=\"color: #008000\">2</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_reshape&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSS&quot;</span>, [ax0, ax1, ax2, ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(conv2_bias[(v_ax1 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax2 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax3) <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> conv2_bias[(v_ax1 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax2 <span style=\"color: #A2F; font-weight: bold\">+</span> v_ax3) <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">64</span>)]\n",
       "\n",
       "    <span style=\"color: #A2F\">@R</span><span style=\"color: #A2F; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">forward</span>(x: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">32</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">64</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">-&gt;</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #A2F; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>dataflow():\n",
       "            lv1 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>reshape, (conv1_bias,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>fused_conv2d_add_relu, (x, conv1_weight, lv1), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv3 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>reshape1, (conv2_bias,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>fused_conv2d1_add1_relu1, (lv, conv2_weight, lv3), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">64</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #A2F; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transforms = [\n",
    "    # # Phase 2. Lowering to TIR, inherited TVM Relax's official \"zero\" pipeline\n",
    "    relax.transform.LegalizeOps(),\n",
    "    relax.transform.AnnotateTIROpPattern(),\n",
    "    relax.transform.FoldConstant(),\n",
    "    relax.transform.FuseOps(),\n",
    "    relax.transform.FuseTIR(),\n",
    "]\n",
    "\n",
    "new_mod = rconv_mod\n",
    "for t in transforms:\n",
    "    new_mod = t(new_mod)\n",
    "\n",
    "new_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9284c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: reshape1\n",
      "    MemBlock(T_reshape:8482231a, shape=(1, 64, 1, 1), dtype=float32, size=256, origin=reshape1)\n",
      "Function: fused_conv2d1_add1_relu1\n",
      "    MemBlock(pad_temp:2f37fa5a, shape=(1, 32, 132, 132), dtype=float32, size=2230272, origin=fused_conv2d1_add1_relu1)\n",
      "    MemBlock(conv2d_nchw_intermediate:f04ff303, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=fused_conv2d1_add1_relu1)\n",
      "    MemBlock(T_add_intermediate:805d1ebb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=fused_conv2d1_add1_relu1)\n",
      "    MemBlock(compute_intermediate:fac748c1, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=fused_conv2d1_add1_relu1)\n",
      "Function: fused_conv2d_add_relu\n",
      "    MemBlock(pad_temp:9066512c, shape=(1, 3, 132, 132), dtype=float32, size=209088, origin=fused_conv2d_add_relu)\n",
      "    MemBlock(conv2d_nchw_intermediate:83fb3d4d, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)\n",
      "    MemBlock(T_add_intermediate:91939108, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)\n",
      "    MemBlock(compute_intermediate:16375aa8, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)\n",
      "Function: forward\n",
      "    MemBlock(x:8bb5d9e1, shape=(1, 3, 128, 128), dtype=float32, size=196608, origin=relax.input)\n",
      "    MemBlock(conv1_weight:6f62c1cf, shape=(32, 3, 5, 5), dtype=float32, size=9600, origin=relax.input)\n",
      "    MemBlock(conv1_bias:daf698da, shape=(32,), dtype=float32, size=128, origin=relax.input)\n",
      "    MemBlock(conv2_weight:65b9869c, shape=(64, 32, 5, 5), dtype=float32, size=204800, origin=relax.input)\n",
      "    MemBlock(conv2_bias:16c149ed, shape=(64,), dtype=float32, size=256, origin=relax.input)\n",
      "    MemBlock(lv1:cd457789, shape=(1, 32, 1, 1), dtype=float32, size=128, origin=relax.call_tir.reshape)\n",
      "    MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu)\n",
      "    MemBlock(lv3:c5e5b528, shape=(1, 64, 1, 1), dtype=float32, size=256, origin=relax.call_tir.reshape1)\n",
      "    MemBlock(gv:bfb394eb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=relax.call_tir.fused_conv2d1_add1_relu1)\n",
      "Function: reshape\n",
      "    MemBlock(T_reshape:e3c040b6, shape=(1, 32, 1, 1), dtype=float32, size=128, origin=reshape)\n"
     ]
    }
   ],
   "source": [
    "alloc_finder = AllocationFinder(new_mod)\n",
    "alloc_finder.walk()\n",
    "\n",
    "for func, mbs in alloc_finder.memblocks.items():\n",
    "    print(f\"Function: {func}\")\n",
    "    for mb in mbs:\n",
    "        print(\"   \", mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9280af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemBlock(pad_temp:9066512c, shape=(1, 3, 132, 132), dtype=float32, size=209088, origin=fused_conv2d_add_relu) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(conv2d_nchw_intermediate:83fb3d4d, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)]\n",
      "MemBlock(conv2d_nchw_intermediate:83fb3d4d, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu) \n",
      "    - Depends on [MemBlock(pad_temp:9066512c, shape=(1, 3, 132, 132), dtype=float32, size=209088, origin=fused_conv2d_add_relu)]\n",
      "    - Links to [MemBlock(T_add_intermediate:91939108, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)]\n",
      "MemBlock(T_add_intermediate:91939108, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu) \n",
      "    - Depends on [MemBlock(conv2d_nchw_intermediate:83fb3d4d, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)]\n",
      "    - Links to [MemBlock(compute_intermediate:16375aa8, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)]\n",
      "MemBlock(compute_intermediate:16375aa8, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu) \n",
      "    - Depends on [MemBlock(T_add_intermediate:91939108, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=fused_conv2d_add_relu)]\n",
      "    - Links to []\n"
     ]
    }
   ],
   "source": [
    "for mb in alloc_finder.memblocks[\"fused_conv2d_add_relu\"]:\n",
    "    print(f\"{mb} \")\n",
    "    print(f\"    - Depends on {mb.depends_on}\")\n",
    "    print(f\"    - Links to {mb.links_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14979644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemBlock(x:8bb5d9e1, shape=(1, 3, 128, 128), dtype=float32, size=196608, origin=relax.input) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu)]\n",
      "MemBlock(conv1_weight:6f62c1cf, shape=(32, 3, 5, 5), dtype=float32, size=9600, origin=relax.input) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu)]\n",
      "MemBlock(conv1_bias:daf698da, shape=(32,), dtype=float32, size=128, origin=relax.input) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(lv1:cd457789, shape=(1, 32, 1, 1), dtype=float32, size=128, origin=relax.call_tir.reshape)]\n",
      "MemBlock(conv2_weight:65b9869c, shape=(64, 32, 5, 5), dtype=float32, size=204800, origin=relax.input) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(gv:bfb394eb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=relax.call_tir.fused_conv2d1_add1_relu1)]\n",
      "MemBlock(conv2_bias:16c149ed, shape=(64,), dtype=float32, size=256, origin=relax.input) \n",
      "    - Depends on []\n",
      "    - Links to [MemBlock(lv3:c5e5b528, shape=(1, 64, 1, 1), dtype=float32, size=256, origin=relax.call_tir.reshape1)]\n",
      "MemBlock(lv1:cd457789, shape=(1, 32, 1, 1), dtype=float32, size=128, origin=relax.call_tir.reshape) \n",
      "    - Depends on [MemBlock(conv1_bias:daf698da, shape=(32,), dtype=float32, size=128, origin=relax.input)]\n",
      "    - Links to [MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu)]\n",
      "MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu) \n",
      "    - Depends on [MemBlock(x:8bb5d9e1, shape=(1, 3, 128, 128), dtype=float32, size=196608, origin=relax.input), MemBlock(conv1_weight:6f62c1cf, shape=(32, 3, 5, 5), dtype=float32, size=9600, origin=relax.input), MemBlock(lv1:cd457789, shape=(1, 32, 1, 1), dtype=float32, size=128, origin=relax.call_tir.reshape)]\n",
      "    - Links to [MemBlock(gv:bfb394eb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=relax.call_tir.fused_conv2d1_add1_relu1)]\n",
      "MemBlock(lv3:c5e5b528, shape=(1, 64, 1, 1), dtype=float32, size=256, origin=relax.call_tir.reshape1) \n",
      "    - Depends on [MemBlock(conv2_bias:16c149ed, shape=(64,), dtype=float32, size=256, origin=relax.input)]\n",
      "    - Links to [MemBlock(gv:bfb394eb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=relax.call_tir.fused_conv2d1_add1_relu1)]\n",
      "MemBlock(gv:bfb394eb, shape=(1, 64, 128, 128), dtype=float32, size=4194304, origin=relax.call_tir.fused_conv2d1_add1_relu1) \n",
      "    - Depends on [MemBlock(lv:d814e86e, shape=(1, 32, 128, 128), dtype=float32, size=2097152, origin=relax.call_tir.fused_conv2d_add_relu), MemBlock(conv2_weight:65b9869c, shape=(64, 32, 5, 5), dtype=float32, size=204800, origin=relax.input), MemBlock(lv3:c5e5b528, shape=(1, 64, 1, 1), dtype=float32, size=256, origin=relax.call_tir.reshape1)]\n",
      "    - Links to []\n"
     ]
    }
   ],
   "source": [
    "for mb in alloc_finder.memblocks[\"forward\"]:\n",
    "    print(f\"{mb} \")\n",
    "    print(f\"    - Depends on {mb.depends_on}\")\n",
    "    print(f\"    - Links to {mb.links_to}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3221d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
